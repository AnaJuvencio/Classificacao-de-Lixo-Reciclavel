# CNN AvanÃ§ada vs MobileNetV2 - Experimento 3

## ðŸŽ¯ Objetivo
Desenvolver uma arquitetura CNN customizada capaz de competir com Transfer Learning (MobileNetV2) na classificaÃ§Ã£o de lixo reciclÃ¡vel.

## ðŸ—ï¸ Arquitetura CNN AvanÃ§ada

### InovaÃ§Ãµes Implementadas:
- **Residual Blocks:** Skip connections para treinar redes profundas sem degradaÃ§Ã£o
- **Squeeze-and-Excitation:** Attention mechanism nos canais para focar em features importantes
- **RegularizaÃ§Ã£o Adaptativa:** Dropout crescente (0.1 â†’ 0.4) por camada
- **Learning Rate Scheduling:** Decaimento exponencial para convergÃªncia otimizada
- **Classificador Robusto:** MÃºltiplas camadas densas com BatchNorm

### Estrutura da Rede:
```
Input (224x224x3)
    â†“
Initial Conv + Pool (7x7, stride=2)
    â†“
Residual Block 1 (64 filters, 2 layers)
    â†“
Residual Block 2 (128 filters, 2 layers, downsample)
    â†“
Residual Block 3 (256 filters, 2 layers, downsample)  
    â†“
Residual Block 4 (512 filters, 2 layers, downsample)
    â†“
Global SE Block (ratio=8)
    â†“
GlobalAveragePooling2D
    â†“
Dense Classifier (512â†’256â†’6)
    â†“
Output (6 classes)
```

## âš”ï¸ CompetiÃ§Ã£o

### Meta: Superar MobileNetV2 (75.10%)

| Modelo | Accuracy | ParÃ¢metros | EstratÃ©gia |
|--------|----------|------------|------------|
| **MobileNetV2 TL** | 75.10% | ~2.3M | Transfer Learning |
| **CNN AvanÃ§ada** | TBD | ~3.5M | From Scratch + Arquitetura AvanÃ§ada |

## ðŸ“Š HipÃ³teses

### Quando CNN AvanÃ§ada pode vencer:
âœ… **Arquitetura otimizada** para classificaÃ§Ã£o de materiais  
âœ… **Attention mechanisms** focam em texturas importantes  
âœ… **Residual connections** permitem rede mais profunda  
âœ… **RegularizaÃ§Ã£o adaptativa** controla overfitting  

### Desafios esperados:
âŒ **Dataset pequeno** (~2.5k imagens) favorece Transfer Learning  
âŒ **Treinamento from scratch** requer mais Ã©pocas  
âŒ **Risco de overfitting** sem features prÃ©-treinadas  

## ðŸ”¬ Metodologia

### ConfiguraÃ§Ã£o Experimental:
- **Dataset:** TrashNet (6 classes: cardboard, glass, metal, paper, plastic, trash)
- **Tamanho:** 224Ã—224 pixels (mesmo do MobileNetV2)
- **Batch Size:** 32
- **Learning Rate:** 5e-5 (com scheduling)
- **Class Weights:** Habilitado (mesmo balanceamento)
- **Early Stopping:** MÃºltiplos critÃ©rios (loss + accuracy)

### EstratÃ©gias de OtimizaÃ§Ã£o:
1. **Callbacks AvanÃ§ados:** ModelCheckpoint + EarlyStopping + ReduceLROnPlateau
2. **RegularizaÃ§Ã£o Multi-nÃ­vel:** Dropout, Weight Decay, BatchNorm
3. **Monitoring:** Accuracy + Top-3 Accuracy para anÃ¡lise detalhada
4. **Comparison Framework:** AvaliaÃ§Ã£o lado-a-lado com MobileNetV2

## ðŸ“ Estrutura de Resultados

```
advanced_cnn_224x224_lr5e-5_bs32/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ advanced_cnn_best.keras          # Melhor modelo treinado
â”œâ”€â”€ plots/
â”‚   â”œâ”€â”€ advanced_cnn_training.png        # Curvas de treinamento
â”‚   â””â”€â”€ cm_advanced_cnn.png              # Matriz de confusÃ£o
â”œâ”€â”€ history/
â”‚   â””â”€â”€ advanced_cnn_history.csv         # HistÃ³rico Ã©pocas
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ advanced_cnn_report.csv          # MÃ©tricas por classe
â”‚   â””â”€â”€ experiment_comparison.json       # ComparaÃ§Ã£o vs MobileNetV2
â””â”€â”€ README.md                            # Esta documentaÃ§Ã£o
```

## ðŸŽ¯ MÃ©tricas de AvaliaÃ§Ã£o

### CritÃ©rios de Sucesso:
- **VitÃ³ria:** CNN > 75.10% (supera MobileNetV2)
- **Empate:** CNN entre 73-75% (competitiva)
- **Derrota honrosa:** CNN > 65% (melhoria significativa vs baseline)
- **Falha:** CNN < 50% (problemas arquiteturais)

### AnÃ¡lises IncluÃ­das:
- âœ… **Performance geral:** Accuracy no conjunto de teste
- âœ… **Performance por classe:** Precision, Recall, F1-Score
- âœ… **AnÃ¡lise visual:** Curvas de treinamento e matrizes de confusÃ£o
- âœ… **ComparaÃ§Ã£o arquitetural:** ParÃ¢metros, complexidade, eficiÃªncia
- âœ… **Tempo de treinamento:** ConvergÃªncia vs MobileNetV2

## ðŸš€ PrÃ³ximos Passos

### Se CNN AvanÃ§ada VENCER:
1. **Documentar inovaÃ§Ãµes** que levaram ao sucesso
2. **Testar em outros datasets** para validar generalizaÃ§Ã£o  
3. **Otimizar arquitetura** para deployment mobile
4. **Investigar ensemble** CNN + MobileNetV2

### Se MobileNetV2 VENCER:
1. **Analisar gaps** da CNN customizada
2. **Testar tÃ©cnicas adicionais:** Data augmentation, Mixup, CutMix
3. **Investigar arquiteturas hÃ­bridas** 
4. **Validar hipÃ³tese** sobre tamanho de dataset

## ðŸ’¡ Valor CientÃ­fico

Este experimento contribui para o entendimento de:
- **Transfer Learning vs From Scratch** em domÃ­nios especÃ­ficos
- **EficÃ¡cia de attention mechanisms** em classificaÃ§Ã£o de materiais
- **Arquiteturas customizadas** vs modelos prÃ©-treinados
- **OtimizaÃ§Ãµes especÃ­ficas** para datasets pequenos

**Status:** ðŸŸ¡ Experimento em andamento  
**Ãšltima atualizaÃ§Ã£o:** 29/11/2025