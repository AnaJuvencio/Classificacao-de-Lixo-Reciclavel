# ğŸ”¬ DocumentaÃ§Ã£o TÃ©cnica - ClassificaÃ§Ã£o de Lixo ReciclÃ¡vel com Deep Learning

## ğŸ“‹ Ãndice
1. [VisÃ£o Geral Arquitetural](#visÃ£o-geral-arquitetural)
2. [Modelos Implementados](#modelos-implementados)
3. [TÃ©cnicas de OtimizaÃ§Ã£o](#tÃ©cnicas-de-otimizaÃ§Ã£o)
4. [Pipeline de Dados](#pipeline-de-dados)
5. [AnÃ¡lise Comparativa](#anÃ¡lise-comparativa)
6. [ImplementaÃ§Ã£o TÃ©cnica](#implementaÃ§Ã£o-tÃ©cnica)

---

##  VisÃ£o Geral Arquitetural

### Stack TecnolÃ³gico
```python
Framework Principal: TensorFlow 2.16.1
Linguagem: Python 3.11
Bibliotecas Auxiliares:
  - scikit-learn (mÃ©tricas e avaliaÃ§Ã£o)
  - pandas (manipulaÃ§Ã£o de dados)
  - matplotlib (visualizaÃ§Ã£o)
  - numpy (operaÃ§Ãµes numÃ©ricas)
```

### Arquitetura do Sistema
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Raw Dataset   â”‚â”€â”€â”€â–¶â”‚  Data Pipeline   â”‚â”€â”€â”€â–¶â”‚  Model Training â”‚
â”‚   (TrashNet)    â”‚    â”‚ (Preprocessing)  â”‚    â”‚   & Evaluation  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚                          â”‚
                              â–¼                          â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Data Augmentationâ”‚    â”‚   Results &     â”‚
                    â”‚   & Validation   â”‚    â”‚  Artifacts      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Modelos Implementados

### 1. CNN Baseline (Convolutional Neural Network do Zero)

#### **O que Ã©:**
Uma rede neural convolucional construÃ­da from scratch, sem usar conhecimento prÃ©-treinado.

#### **Arquitetura Detalhada:**
```python
Model: "cnn_baseline"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 160, 160, 32)     864       
 batch_normalization         (None, 160, 160, 32)     128       
 re_lu (ReLU)                (None, 160, 160, 32)     0         
 max_pooling2d               (None, 80, 80, 32)       0         
 dropout (Dropout)           (None, 80, 80, 32)       0         
                                                                 
 conv2d_1 (Conv2D)           (None, 80, 80, 64)       18432     
 batch_normalization_1       (None, 80, 80, 64)       256       
 re_lu_1 (ReLU)              (None, 80, 80, 64)       0         
 max_pooling2d_1             (None, 40, 40, 64)       0         
 dropout_1 (Dropout)         (None, 40, 40, 64)       0         
                                                                 
 conv2d_2 (Conv2D)           (None, 40, 40, 128)      73728     
 batch_normalization_2       (None, 40, 40, 128)      512       
 re_lu_2 (ReLU)              (None, 40, 40, 128)      0         
 max_pooling2d_2             (None, 20, 20, 128)      0         
 dropout_2 (Dropout)         (None, 20, 20, 128)      0         
                                                                 
 global_average_pooling2d    (None, 128)               0         
 dense (Dense)               (None, 256)               33024     
 dropout_3 (Dropout)         (None, 256)               0         
 dense_1 (Dense)             (None, 6)                 1542      
=================================================================
Total params: 128,486 (501.90 KB)
Trainable params: 128,038 (500.15 KB)
Non-trainable params: 448 (1.75 KB)
```

#### **Componentes Explicados:**

**1. Camadas Convolucionais (Conv2D):**
```python
layers.Conv2D(filters, kernel_size, padding="same", use_bias=False)
```
- **FunÃ§Ã£o:** ExtraÃ§Ã£o de features espaciais (bordas, texturas, formas)
- **Filters:** 32 â†’ 64 â†’ 128 (progressÃ£o hierÃ¡rquica)
- **Kernel 3x3:** Janela deslizante para detecÃ§Ã£o de padrÃµes locais
- **use_bias=False:** Bias Ã© manipulado pelo BatchNormalization

**2. Batch Normalization:**
```python
layers.BatchNormalization()
```
- **FunÃ§Ã£o:** Normaliza entradas de cada camada
- **BenefÃ­cios:** Acelera convergÃªncia, reduz overfitting, estabiliza gradientes
- **MatemÃ¡tica:** `y = Î³(x - Î¼)/Ïƒ + Î²` onde Î¼, Ïƒ sÃ£o mÃ©dia e desvio do batch

**3. FunÃ§Ã£o de AtivaÃ§Ã£o ReLU:**
```python
layers.ReLU()
```
- **FunÃ§Ã£o:** `f(x) = max(0, x)`
- **Vantagens:** Evita vanishing gradient, computacionalmente eficiente
- **NÃ£o-linearidade:** Permite aprender padrÃµes complexos

**4. Max Pooling:**
```python
layers.MaxPooling2D(pool_size=(2,2))
```
- **FunÃ§Ã£o:** ReduÃ§Ã£o dimensional (downsampling)
- **BenefÃ­cios:** Reduz parÃ¢metros, aumenta campo receptivo, invariÃ¢ncia translacional

**5. Dropout:**
```python
layers.Dropout(rate)
```
- **FunÃ§Ã£o:** RegularizaÃ§Ã£o atravÃ©s de "desligamento" aleatÃ³rio de neurÃ´nios
- **Taxa 0.3:** 30% dos neurÃ´nios sÃ£o zerados durante treino
- **PrevenÃ§Ã£o:** Overfitting e co-adaptaÃ§Ã£o de features

**6. Global Average Pooling:**
```python
layers.GlobalAveragePooling2D()
```
- **FunÃ§Ã£o:** Converte feature maps em vetores 1D
- **Vantagem vs Flatten:** Reduz drasticamente parÃ¢metros, menos overfitting
- **OperaÃ§Ã£o:** MÃ©dia de todos valores em cada canal

### 2. MobileNetV2 Transfer Learning

#### **O que Ã©:**
Aproveitamento de uma rede prÃ©-treinada (MobileNetV2) para nova tarefa de classificaÃ§Ã£o.

#### **MobileNetV2 - Conceitos Fundamentais:**

**1. Depthwise Separable Convolutions:**
```python
# Convolution tradicional: O(H Ã— W Ã— C_in Ã— C_out Ã— KÂ²)
# Depthwise Separable: O(H Ã— W Ã— C_in Ã— KÂ²) + O(H Ã— W Ã— C_in Ã— C_out)
```
- **ReduÃ§Ã£o computacional:** ~8-9x menos operaÃ§Ãµes
- **MantÃ©m performance:** AtravÃ©s de separaÃ§Ã£o de responsabilidades

**2. Inverted Residuals:**
```python
# SequÃªncia: 1x1 expand â†’ 3x3 depthwise â†’ 1x1 project
input â†’ [1Ã—1 conv] â†’ [3Ã—3 depthwise] â†’ [1Ã—1 conv] â†’ output
      (expand)     (spatial mixing)    (compress)
```

**3. Linear Bottlenecks:**
- Ãšltima camada sem ativaÃ§Ã£o nÃ£o-linear
- Preserva informaÃ§Ã£o em espaÃ§os de baixa dimensÃ£o

#### **EstratÃ©gia de Transfer Learning:**

**Fase 1 - Feature Extraction (Frozen Base):**
```python
base.trainable = False  # Congela todos os pesos prÃ©-treinados
```
- **DuraÃ§Ã£o:** 8 Ã©pocas
- **Learning Rate:** 1e-4
- **Objetivo:** Adaptar apenas o classificador

**Fase 2 - Fine-tuning (Partial Unfreezing):**
```python
base.trainable = True
for layer in base.layers[:-40]:  # Descongela apenas Ãºltimas 40 camadas
    layer.trainable = False
```
- **DuraÃ§Ã£o:** 7 Ã©pocas  
- **Learning Rate:** 1e-4 (mesmo valor, pois jÃ¡ estÃ¡ baixo)
- **Objetivo:** Ajuste fino das features de alto nÃ­vel

---

##  TÃ©cnicas de OtimizaÃ§Ã£o

### 1. Otimizador AdamW

#### **O que Ã©:**
Variante do Adam com weight decay desacoplado.

#### **Funcionamento:**
```python
# Adam tradicional
m_t = Î²â‚ Ã— m_{t-1} + (1-Î²â‚) Ã— g_t
v_t = Î²â‚‚ Ã— v_{t-1} + (1-Î²â‚‚) Ã— g_tÂ²
Î¸_{t+1} = Î¸_t - Î± Ã— mÌ‚_t / (âˆšvÌ‚_t + Îµ)

# AdamW adiciona
Î¸_{t+1} = Î¸_{t+1} - Î± Ã— Î» Ã— Î¸_t  # weight decay desacoplado
```

#### **Vantagens sobre Adam:**
- **Weight decay real:** NÃ£o afetado pela adaptaÃ§Ã£o da learning rate
- **Melhor generalizaÃ§Ã£o:** RegularizaÃ§Ã£o mais efetiva
- **ConvergÃªncia superior:** Especialmente em tasks de visÃ£o computacional

### 2. Learning Rate Scheduling

#### **ReduceLROnPlateau:**
```python
keras.callbacks.ReduceLROnPlateau(
    monitor="val_loss", 
    factor=0.5,        # Reduz LR pela metade
    patience=3,        # ApÃ³s 3 Ã©pocas sem melhoria
    min_lr=1e-6       # LR mÃ­nimo
)
```

**MatemÃ¡tica:**
```
LR_new = LR_current Ã— factor  se val_loss nÃ£o melhorar por 'patience' Ã©pocas
```

### 3. Early Stopping

#### **Funcionamento:**
```python
keras.callbacks.EarlyStopping(
    monitor="val_loss",
    patience=6,
    restore_best_weights=True
)
```
- **PrevenÃ§Ã£o:** Overfitting
- **EficiÃªncia:** Para treino quando nÃ£o hÃ¡ mais melhoria
- **Restore:** Volta aos melhores pesos encontrados

### 4. Model Checkpointing

#### **ImplementaÃ§Ã£o:**
```python
keras.callbacks.ModelCheckpoint(
    "modelo_best.keras",
    monitor="val_accuracy",
    save_best_only=True
)
```
- **FunÃ§Ã£o:** Salva apenas o melhor modelo durante treino
- **CritÃ©rio:** Maior acurÃ¡cia de validaÃ§Ã£o

---

## Pipeline de Dados

### 1. Carregamento e DivisÃ£o

#### **EstratÃ©gia de Split:**
```python
# 80% treino, 20% validaÃ§Ã£o/teste
train_ds = 80% (2022 imagens)
val_ds = 10% (253 imagens)  
test_ds = 10% (252 imagens)
```

#### **ImplementaÃ§Ã£o tf.data:**
```python
train_base = tf.keras.utils.image_dataset_from_directory(
    DATA_DIR,
    validation_split=0.2, 
    subset="training",
    seed=SEED,              # Reprodutibilidade
    image_size=(160, 160),  # Resize automÃ¡tico
    batch_size=16
)
```

### 2. Preprocessing Pipeline

#### **NormalizaÃ§Ã£o:**
```python
normalizer = tf.keras.layers.Rescaling(1./255)
# Converte [0, 255] â†’ [0, 1]
```

#### **Data Augmentation:**
```python
augment = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal"),    # Flip horizontal aleatÃ³rio
    tf.keras.layers.RandomRotation(0.03),        # RotaÃ§Ã£o Â±3Â°
    tf.keras.layers.RandomZoom(0.05),           # Zoom Â±5%
])
```

**Por que essas transformaÃ§Ãµes?**
- **RandomFlip:** Lixo pode aparecer em qualquer orientaÃ§Ã£o
- **RotaÃ§Ã£o pequena:** Objetos podem estar ligeiramente inclinados
- **Zoom leve:** Simula diferentes distÃ¢ncias da cÃ¢mera

### 3. OtimizaÃ§Ã£o de Performance

#### **tf.data Pipeline:**
```python
dataset = dataset.map(prep_function, num_parallel_calls=tf.data.AUTOTUNE)
dataset = dataset.prefetch(tf.data.AUTOTUNE)
```

**ExplicaÃ§Ã£o:**
- **map + AUTOTUNE:** ParalelizaÃ§Ã£o automÃ¡tica do preprocessing
- **prefetch:** Carrega prÃ³ximo batch enquanto treina o atual
- **Resultado:** Reduz tempo de I/O significativamente

---

## âš–ï¸ AnÃ¡lise Comparativa

### Performance Computacional

| Aspecto | CNN Baseline | MobileNetV2 TL |
|---------|--------------|----------------|
| **ParÃ¢metros** | 128K | ~2.3M |
| **Tamanho Modelo** | 500KB | ~9MB |
| **Tempo/Ã‰poca** | ~70s | ~30s |
| **MemÃ³ria GPU** | Baixo | MÃ©dio |
| **InferÃªncia** | RÃ¡pida | Muito RÃ¡pida |

### Complexidade Algoritmica

#### **CNN Baseline:**
```
Complexidade Treino: O(E Ã— B Ã— H Ã— W Ã— F Ã— KÂ²)
onde:
E = Ã©pocas, B = batch_size, HÃ—W = dimensÃµes imagem
F = filtros, K = kernel_size
```

#### **MobileNetV2:**
```
Complexidade Treino: O(E Ã— B Ã— H Ã— W Ã— (C + F))
onde C = canais entrada, F = fator expansÃ£o
ReduÃ§Ã£o: ~8-9x devido Ã s depthwise separable convolutions
```

### Trade-offs

| Modelo | Vantagens | Desvantagens |
|--------|-----------|--------------|
| **CNN Baseline** | â€¢ Controle total da arquitetura<br>â€¢ Modelo leve<br>â€¢ InterpretÃ¡vel | â€¢ Performance limitada<br>â€¢ Treino do zero<br>â€¢ Requer mais dados |
| **MobileNetV2** | â€¢ Alta performance<br>â€¢ ConvergÃªncia rÃ¡pida<br>â€¢ Features robustas | â€¢ Modelo maior<br>â€¢ Menos controle<br>â€¢ DependÃªncia do prÃ©-treino |

---

## ğŸ”§ ImplementaÃ§Ã£o TÃ©cnica

### 1. Gerenciamento de MemÃ³ria

#### **EstratÃ©gias Aplicadas:**
```python
# Batch size otimizado para CPU
BATCH_SIZE = 16  # BalanÃ§o entre convergÃªncia e memÃ³ria

# Mixed precision (se GPU disponÃ­vel)
policy = tf.keras.mixed_precision.Policy('mixed_float16')
tf.keras.mixed_precision.set_global_policy(policy)
```

### 2. Reprodutibilidade

#### **Seeds DeterminÃ­sticos:**
```python
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)
os.environ['PYTHONHASHSEED'] = str(SEED)
```

### 3. Tratamento de Desbalanceamento

#### **Class Weights Calculados:**
```python
class_weight = {
    cls: total_samples / (num_classes Ã— samples_per_class)
    for cls, samples_per_class in class_counts.items()
}
```

**MatemÃ¡tica:**
```
weight_i = N / (C Ã— N_i)
onde:
N = total de amostras
C = nÃºmero de classes  
N_i = amostras da classe i
```

### 4. MÃ©tricas de AvaliaÃ§Ã£o

#### **ImplementaÃ§Ã£o Completa:**
```python
# MÃ©tricas por classe
precision, recall, f1, support = precision_recall_fscore_support(
    y_true, y_pred, 
    labels=range(NUM_CLASSES),
    average=None
)

# Matriz de confusÃ£o
cm = confusion_matrix(y_true, y_pred)
cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)
```

### 5. Salvamento e SerializaÃ§Ã£o

#### **Formato Keras:**
```python
model.save("modelo.keras")  # Formato nativo TensorFlow 2.x
```

**Vantagens do .keras:**
- **Completo:** Arquitetura + pesos + otimizador
- **Compatibilidade:** Futuras versÃµes TensorFlow
- **Portabilidade:** Entre diferentes plataformas

---

## ğŸ¯ ConclusÃµes TÃ©cnicas

### LiÃ§Ãµes Aprendidas

1. **Transfer Learning Ã© Superior:**
   - Features prÃ©-treinadas no ImageNet sÃ£o transferÃ­veis
   - Reduz significativamente tempo de treino
   - Melhora generalizaÃ§Ã£o em datasets pequenos

2. **RegularizaÃ§Ã£o Ã© Crucial:**
   - Dropout previne overfitting efetivamente
   - BatchNormalization acelera convergÃªncia
   - Weight decay melhora generalizaÃ§Ã£o

3. **Pipeline Otimizado Importa:**
   - tf.data reduz gargalos de I/O
   - Data augmentation aumenta diversidade
   - Preprocessing eficiente acelera treino

### RecomendaÃ§Ãµes para ProduÃ§Ã£o

1. **Modelo Recomendado:** MobileNetV2 Transfer Learning
2. **Deployment:** TensorFlow Lite para mobile
3. **Monitoramento:** Drift detection nas prediÃ§Ãµes
4. **Retreino:** Quando acurÃ¡cia cair abaixo de threshold

---

**Autor:** Equipe de ML Engineering  
**Data:** Outubro 2025  
**VersÃ£o TÃ©cnica:** 1.0